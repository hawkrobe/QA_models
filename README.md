# PragmaticQA: Pragmatic reasoning about (polar) questions and (over-informative) answers

This repository contains:

- `01-old_models`: implementations of pragmatic reasoning models (in WebPPL) with code for data analysis from original work (prior to 2021; work done by RDH & NDG); these models rely on QUDs to represent questioner goals
- `02-deprecated-model-variants`: impplementations of an updated model variant (after 2021; done my RDH, MF, and NDG); main changes to previous models: (i) questioner goals as numeric utilities in a decision problem; (ii) grounding reasoning in notion of `safe answer` (see `02-deprecated-model-variants/safe-answers-sequential-decisions.html`); models at this stage only included predictions for the choice of question (no preference inference, no pragmatic answer choice); (roughly up to the point of the 2021 CogSci Colloquium presentation @ TÃ¼bingen)
- `03-current-models-webppl`: extended modeling code that also includes the pragmatic answerer (see `03-current-models-webppl/README.md` for details).
- `04-GPT3-tests`: code for testing LH of (overinformative) answers to (polar) questions for GPT3 ("text-davinci-002"); this investigation into LLMs' ability to generate pragmatic, human-like responses is continued in a separate repo [here](https://github.com/magpie-ea/magpie3-qa-overinfo-free-production)
- `05-preference-elicitation`: code and results from a pilot experiment to elicit data on preference (to be fed into the models)
- `pics`: plots and visuals generated by some analysis scripts
